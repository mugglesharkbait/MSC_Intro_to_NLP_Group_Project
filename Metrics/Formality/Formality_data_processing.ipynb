{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 199.4/199.4 kB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas nltk chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having tab-separated files\n",
    "answers = 'annotated_sentences/answers.tsv'\n",
    "blog = 'annotated_sentences/blog.tsv'\n",
    "email = 'annotated_sentences/email.tsv'\n",
    "news = 'annotated_sentences/news.tsv'\n",
    "file_paths = [answers, blog, email, news]\n",
    "encodings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect encoding for each file\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        encodings.append(chardet.detect(file.read())['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    dfs = []\n",
    "    i = 0\n",
    "    for file_path in file_paths:\n",
    "        # Read the tab-separated data using pandas\n",
    "        df = pd.read_csv(file_path, sep='\\t', encoding=encodings[i],header=None)\n",
    "        i += 1\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    # Create dictionaries to store n-gram data\n",
    "    ngram_data = {1: defaultdict(lambda: [0, 0,0]),\n",
    "                  2: defaultdict(lambda: [0, 0,0]),\n",
    "                  3: defaultdict(lambda: [0, 0,0]),\n",
    "                  4: defaultdict(lambda: [0, 0,0]),\n",
    "                  5: defaultdict(lambda: [0, 0,0])}\n",
    "\n",
    "    # Process each row efficiently using vectorized operations\n",
    "    for index, row in df.iterrows():\n",
    "        score = float(row[0])\n",
    "        sentence = row[3]\n",
    "\n",
    "        for n in range(1, 6):\n",
    "            ngrams_list = list(ngrams(sentence.split(), n))\n",
    "            for ngram in ngrams_list:\n",
    "                ngram_key = ' '.join(ngram)\n",
    "                ngram_data[n][ngram_key][0] += score\n",
    "                ngram_data[n][ngram_key][1] += 1\n",
    "                ngram_data[n][ngram_key][2] = ngram_data[n][ngram_key][0]/ngram_data[n][ngram_key][1]\n",
    "\n",
    "    # Write n-gram data to separate txt files\n",
    "    for n in range(1, 6):\n",
    "        output_file = f'./annotated_ngrams/{n}-gram.txt'\n",
    "        ngram_df = pd.DataFrame.from_dict(ngram_data[n], orient='index', columns=['total_score', 'total_occurrences','average_score'])\n",
    "        ngram_df.index.name = 'n-gram'\n",
    "        ngram_df.reset_index(inplace=True)\n",
    "        ngram_df.to_csv(output_file, sep='\\t', index=False)\n",
    "        print(f\"Data successfully processed and written to files in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully processed and written to files in ./output/1-gram.txt\n",
      "Data successfully processed and written to files in ./output/2-gram.txt\n",
      "Data successfully processed and written to files in ./output/3-gram.txt\n",
      "Data successfully processed and written to files in ./output/4-gram.txt\n",
      "Data successfully processed and written to files in ./output/5-gram.txt\n"
     ]
    }
   ],
   "source": [
    "df = read_data()\n",
    "process(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
