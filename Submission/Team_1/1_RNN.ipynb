{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmdXVBAWGpsM"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:10.893619Z",
     "iopub.status.busy": "2024-02-10T22:13:10.893413Z",
     "iopub.status.idle": "2024-02-10T22:13:10.896637Z",
     "shell.execute_reply": "2024-02-10T22:13:10.896004Z",
     "shell.execute_reply.started": "2024-02-10T22:13:10.893596Z"
    },
    "id": "OeY28k58DG8T",
    "outputId": "289ac94e-d2a8-4260-8048-dbadc5637fb3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:10.898467Z",
     "iopub.status.busy": "2024-02-10T22:13:10.898031Z",
     "iopub.status.idle": "2024-02-10T22:13:10.901759Z",
     "shell.execute_reply": "2024-02-10T22:13:10.901004Z",
     "shell.execute_reply.started": "2024-02-10T22:13:10.898444Z"
    },
    "id": "L-kDQGv4DMWY",
    "outputId": "67d3b175-cb24-446c-cd44-839e76601de7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/MSC_Intro_to_NLP_Group_Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:10.903331Z",
     "iopub.status.busy": "2024-02-10T22:13:10.902853Z",
     "iopub.status.idle": "2024-02-10T22:13:33.733361Z",
     "shell.execute_reply": "2024-02-10T22:13:33.732520Z",
     "shell.execute_reply.started": "2024-02-10T22:13:10.903307Z"
    },
    "id": "Jf8V8EEnGpsO",
    "outputId": "df02b335-c881-46f9-f2dd-9ddbfb1f8346",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: gensim in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gensim) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: transformers[torch] in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.11 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from transformers[torch]) (0.27.0)\n",
      "Requirement already satisfied: psutil in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests->transformers[torch]) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: datasets in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.4)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: torch in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: contractions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install 'transformers[torch]'\n",
    "!pip install datasets\n",
    "!pip install tensorflow\n",
    "!pip install torch\n",
    "!pip install contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:33.734927Z",
     "iopub.status.busy": "2024-02-10T22:13:33.734551Z",
     "iopub.status.idle": "2024-02-10T22:13:44.330867Z",
     "shell.execute_reply": "2024-02-10T22:13:44.329957Z",
     "shell.execute_reply.started": "2024-02-10T22:13:33.734902Z"
    },
    "id": "dsTI9k5EGpsP",
    "outputId": "29a59ae8-d5d8-440c-c69b-dc5c13cf7594"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.4)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import contractions\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:44.333394Z",
     "iopub.status.busy": "2024-02-10T22:13:44.332361Z",
     "iopub.status.idle": "2024-02-10T22:13:44.341537Z",
     "shell.execute_reply": "2024-02-10T22:13:44.340621Z",
     "shell.execute_reply.started": "2024-02-10T22:13:44.333353Z"
    },
    "id": "QS55Y89QZpgm",
    "outputId": "5e6b340b-1481-4d2a-8baf-5d5eb2f74906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Using the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "gpu_name = torch.cuda.get_device_name(device)\n",
    "print(gpu_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:44.342783Z",
     "iopub.status.busy": "2024-02-10T22:13:44.342542Z",
     "iopub.status.idle": "2024-02-10T22:13:44.966883Z",
     "shell.execute_reply": "2024-02-10T22:13:44.966237Z",
     "shell.execute_reply.started": "2024-02-10T22:13:44.342760Z"
    },
    "id": "dAoiwoKfZpgm"
   },
   "outputs": [],
   "source": [
    "# Load spaCy model outside of the function to avoid reloading it each time the function is called\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCypnUdGFJDB"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:44.970658Z",
     "iopub.status.busy": "2024-02-10T22:13:44.970333Z",
     "iopub.status.idle": "2024-02-10T22:13:44.977365Z",
     "shell.execute_reply": "2024-02-10T22:13:44.976643Z",
     "shell.execute_reply.started": "2024-02-10T22:13:44.970633Z"
    },
    "id": "TiyOveU2Zpgm"
   },
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "# Function to capitalize the first letter of each sentence and proper nouns\n",
    "def capitalize_first_and_proper_nouns(text):\n",
    "    # Process the text using spaCy to create a Doc object\n",
    "    doc = nlp(text)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # Iterate over the sentences in the Doc\n",
    "    for sent in doc.sents:\n",
    "        # Iterate over the tokens in the sentence\n",
    "        for token in sent:\n",
    "            # Capitalize the first letter of each sentence and proper nouns\n",
    "            if token.is_sent_start or token.pos_ == 'PROPN':\n",
    "                result.append(token.text.capitalize())\n",
    "            else:\n",
    "                result.append(token.text)\n",
    "\n",
    "    # Rejoin the tokens into a single string\n",
    "    return ' '.join(result)\n",
    "\n",
    "# Function to remove repeated punctuations\n",
    "def remove_repeated_punctuations(sentence):\n",
    "    # Use regular expression to remove consecutive repeated punctuations\n",
    "    cleaned_sentence = re.sub(r'(\\W)\\1+', r'\\1', sentence)\n",
    "    return cleaned_sentence\n",
    "\n",
    "# Function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# Define a tokenization function\n",
    "def tokenize_sentences(sentences):\n",
    "    return [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "def fix_general_spacing(sentence):\n",
    "    # Fix space before punctuation (like ' ,' to ',')\n",
    "    sentence = re.sub(r'\\s([,.?!:;])', r'\\1', sentence)\n",
    "    # Fix space after punctuation (like ' . ' to '. ')\n",
    "    sentence = re.sub(r'([,.?!:;])\\s', r'\\1 ', sentence)\n",
    "    # Fix space in contractions (like \"don 't\" to \"don't\")\n",
    "    sentence = re.sub(r\"\\b(\\w+)\\s('t|'s|'m|'ll|'ve|'re|'d|n't)\\b\", r\"\\1\\2\", sentence)\n",
    "    # Reduce multiple spaces between words to a single space\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "def preprocess(text):\n",
    "    # text = text.lower()\n",
    "    text = expand_contractions(text)\n",
    "    text = remove_repeated_punctuations(text)\n",
    "    text = capitalize_first_and_proper_nouns(text)\n",
    "    text = fix_general_spacing(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:44.979050Z",
     "iopub.status.busy": "2024-02-10T22:13:44.978529Z",
     "iopub.status.idle": "2024-02-10T22:13:45.570230Z",
     "shell.execute_reply": "2024-02-10T22:13:45.569581Z",
     "shell.execute_reply.started": "2024-02-10T22:13:44.979014Z"
    },
    "id": "249pORAGZpgm"
   },
   "outputs": [],
   "source": [
    "# Load the preprocessed data from the JSON file\n",
    "# data_files={\n",
    "#     \"train\":\"data_train.json\",\n",
    "# }\n",
    "\n",
    "# dataset = load_dataset(\"json\", data_files=data_files)\n",
    "# print(dataset)\n",
    "\n",
    "json_file_path = \"data_train.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    dataset = json.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3LhyQlHZpgn"
   },
   "source": [
    "# A dataset class to load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.571540Z",
     "iopub.status.busy": "2024-02-10T22:13:45.571222Z",
     "iopub.status.idle": "2024-02-10T22:13:45.576558Z",
     "shell.execute_reply": "2024-02-10T22:13:45.575834Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.571516Z"
    },
    "id": "AY40VS7kZpgn"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"id\": item[\"id\"],\n",
    "            \"topic\": item[\"topic\"],\n",
    "            \"input_seq\": torch.tensor(item[\"input_seq\"]),\n",
    "            \"output_seq\": torch.tensor(item[\"output_seq\"]),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDzIXXWAZpgn"
   },
   "source": [
    "# Creating a Bi-Directional RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.577797Z",
     "iopub.status.busy": "2024-02-10T22:13:45.577502Z",
     "iopub.status.idle": "2024-02-10T22:13:45.583014Z",
     "shell.execute_reply": "2024-02-10T22:13:45.582458Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.577775Z"
    },
    "id": "EoFBCnZVZpgn"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the whole dataset's informal sentences\n",
    "def preprocess_data(data):\n",
    "    for item in data:\n",
    "        item[\"transformation\"][\"informal\"] = preprocess(item[\"transformation\"][\"informal\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.584621Z",
     "iopub.status.busy": "2024-02-10T22:13:45.583982Z",
     "iopub.status.idle": "2024-02-10T22:13:45.587734Z",
     "shell.execute_reply": "2024-02-10T22:13:45.586996Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.584585Z"
    },
    "id": "bn7qcSwQZpgn"
   },
   "outputs": [],
   "source": [
    "# preprocessed_data = preprocess_data(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.588869Z",
     "iopub.status.busy": "2024-02-10T22:13:45.588586Z",
     "iopub.status.idle": "2024-02-10T22:13:45.593097Z",
     "shell.execute_reply": "2024-02-10T22:13:45.592362Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.588848Z"
    },
    "id": "n1tNj1tfZpgn"
   },
   "outputs": [],
   "source": [
    "# tokenizing the whole dataset\n",
    "def tokenize_data(data):\n",
    "    for item in data:\n",
    "        item[\"tokenized_informal\"] = word_tokenize(item[\"transformation\"][\"informal\"])\n",
    "        item[\"tokenized_formal\"] = word_tokenize(item[\"transformation\"][\"formal.ref0\"])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.594724Z",
     "iopub.status.busy": "2024-02-10T22:13:45.594166Z",
     "iopub.status.idle": "2024-02-10T22:13:45.599988Z",
     "shell.execute_reply": "2024-02-10T22:13:45.599449Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.594689Z"
    },
    "id": "Z_6RS2IgZpgn"
   },
   "outputs": [],
   "source": [
    "# assigning indices to each unique word and creating a vocabulary\n",
    "def build_vocab(data):\n",
    "    input_vocab = set()\n",
    "    output_vocab = set()\n",
    "\n",
    "    for item in data:\n",
    "        input_vocab.update(item[\"tokenized_informal\"])\n",
    "        output_vocab.update(item[\"tokenized_formal\"])\n",
    "\n",
    "    input_vocab = {word: idx for idx, word in enumerate(input_vocab)}\n",
    "    output_vocab = {word: idx for idx, word in enumerate(output_vocab)}\n",
    "\n",
    "    return input_vocab, output_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.601661Z",
     "iopub.status.busy": "2024-02-10T22:13:45.601277Z",
     "iopub.status.idle": "2024-02-10T22:13:45.606312Z",
     "shell.execute_reply": "2024-02-10T22:13:45.605625Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.601637Z"
    },
    "id": "RTgJBYycZpgn"
   },
   "outputs": [],
   "source": [
    "# function for padding the sequence with max length provided\n",
    "def pad_sequence(sequence, max_length, vocab):\n",
    "    padded_sequence = [vocab[word] for word in sequence if word in vocab]\n",
    "    padded_sequence += [0] * (max_length - len(padded_sequence))\n",
    "    return padded_sequence\n",
    "\n",
    "# function to convert tokenized informal and formal sentences in the dataset using padding of 65 tokens\n",
    "def numericalize_data(data, input_vocab, output_vocab):\n",
    "#     max_input_length = max(len(item[\"tokenized_informal\"]) for item in data)\n",
    "#     max_output_length = max(len(item[\"tokenized_formal\"]) for item in data)\n",
    "    max_input_length = 65\n",
    "    max_output_length = 65\n",
    "\n",
    "    for item in data:\n",
    "        item[\"input_seq\"] = pad_sequence(item[\"tokenized_informal\"], max_input_length, input_vocab)\n",
    "        item[\"output_seq\"] = pad_sequence(item[\"tokenized_formal\"], max_output_length, output_vocab)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMm8J8TmZpgn"
   },
   "source": [
    "## Defining a Bi-Directional RNN Model using LSTM from Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.607454Z",
     "iopub.status.busy": "2024-02-10T22:13:45.607176Z",
     "iopub.status.idle": "2024-02-10T22:13:45.611897Z",
     "shell.execute_reply": "2024-02-10T22:13:45.611327Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.607434Z"
    },
    "id": "3yI-IWO6Zpgn"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        output = self.fc(output)\n",
    "        return torch.nn.functional.log_softmax(output, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.613015Z",
     "iopub.status.busy": "2024-02-10T22:13:45.612708Z",
     "iopub.status.idle": "2024-02-10T22:13:45.617861Z",
     "shell.execute_reply": "2024-02-10T22:13:45.617162Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.612993Z"
    },
    "id": "5D6EF6jBZpgn"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            inputs = batch[\"input_seq\"].to(device)\n",
    "            targets = batch[\"output_seq\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, len(output_vocab)), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDOy2r78Zpgn"
   },
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:13:45.618998Z",
     "iopub.status.busy": "2024-02-10T22:13:45.618696Z",
     "iopub.status.idle": "2024-02-10T22:26:39.187408Z",
     "shell.execute_reply": "2024-02-10T22:26:39.186734Z",
     "shell.execute_reply.started": "2024-02-10T22:13:45.618975Z"
    },
    "id": "LEBBgy0GZpgn"
   },
   "outputs": [],
   "source": [
    "data = preprocess_data(dataset)\n",
    "data = tokenize_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:26:39.188730Z",
     "iopub.status.busy": "2024-02-10T22:26:39.188370Z",
     "iopub.status.idle": "2024-02-10T22:26:41.930129Z",
     "shell.execute_reply": "2024-02-10T22:26:41.929462Z",
     "shell.execute_reply.started": "2024-02-10T22:26:39.188688Z"
    },
    "id": "fYQptumaKc42"
   },
   "outputs": [],
   "source": [
    "with open(\"./data_train_preprocess_n_token.json\", 'w') as f:\n",
    "  json.dump(data, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:26:41.931715Z",
     "iopub.status.busy": "2024-02-10T22:26:41.931293Z",
     "iopub.status.idle": "2024-02-10T22:26:41.936698Z",
     "shell.execute_reply": "2024-02-10T22:26:41.935941Z",
     "shell.execute_reply.started": "2024-02-10T22:26:41.931676Z"
    },
    "id": "qB5Kpq14Zpgo",
    "outputId": "2df5bf7c-89ec-4b37-ffff-ce880b035414",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'topic': 'Family_Relationships', 'transformation': {'informal': 'Hmmm, I am a guy suffering from verbal abuse from my wife.', 'formal.ref0': 'I suffer through verbal abuse from my wife.', 'formal.ref1': '', 'formal.ref2': '', 'formal.ref3': ''}, 'tokenized_informal': ['Hmmm', ',', 'I', 'am', 'a', 'guy', 'suffering', 'from', 'verbal', 'abuse', 'from', 'my', 'wife', '.'], 'tokenized_formal': ['I', 'suffer', 'through', 'verbal', 'abuse', 'from', 'my', 'wife', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:26:41.938007Z",
     "iopub.status.busy": "2024-02-10T22:26:41.937577Z",
     "iopub.status.idle": "2024-02-10T22:26:43.452523Z",
     "shell.execute_reply": "2024-02-10T22:26:43.451878Z",
     "shell.execute_reply.started": "2024-02-10T22:26:41.937984Z"
    },
    "id": "JKWbIHZCZpgo"
   },
   "outputs": [],
   "source": [
    "# numericalizing the data\n",
    "input_vocab, output_vocab = build_vocab(data)\n",
    "data = numericalize_data(data, input_vocab, output_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:26:43.453762Z",
     "iopub.status.busy": "2024-02-10T22:26:43.453428Z",
     "iopub.status.idle": "2024-02-10T22:26:43.458866Z",
     "shell.execute_reply": "2024-02-10T22:26:43.458062Z",
     "shell.execute_reply.started": "2024-02-10T22:26:43.453715Z"
    },
    "id": "TDes1lnUZpgo",
    "outputId": "152dfc3e-753f-4516-c181-02761fb15de3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104562\n",
      "input_seq: \n",
      "65\n",
      "[46250, 3156, 12762, 6609, 5753, 3156, 45679, 34319, 33475, 47083, 13699, 2022, 27820, 14588, 40840, 260, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "output_seq: \n",
      "65\n",
      "[24464, 23963, 8444, 9839, 1421, 19827, 10471, 29155, 180, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(\"input_seq: \")\n",
    "print(len(data[0]['input_seq']))\n",
    "print(data[0]['input_seq'])\n",
    "print(\"output_seq: \")\n",
    "print(len(data[0]['output_seq']))\n",
    "print(data[0]['output_seq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:26:43.463948Z",
     "iopub.status.busy": "2024-02-10T22:26:43.463646Z",
     "iopub.status.idle": "2024-02-10T22:26:43.467940Z",
     "shell.execute_reply": "2024-02-10T22:26:43.467124Z",
     "shell.execute_reply.started": "2024-02-10T22:26:43.463926Z"
    },
    "id": "m9StD9p2Zpgo"
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "train_data = data\n",
    "train_dataset = CustomDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T22:26:43.469210Z",
     "iopub.status.busy": "2024-02-10T22:26:43.468963Z",
     "iopub.status.idle": "2024-02-10T22:26:44.698976Z",
     "shell.execute_reply": "2024-02-10T22:26:44.698170Z",
     "shell.execute_reply.started": "2024-02-10T22:26:43.469170Z"
    },
    "id": "TOnjNLy_Zpgo"
   },
   "outputs": [],
   "source": [
    "# getting everything together for the model\n",
    "model = RNN(len(input_vocab), 256, len(output_vocab)).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T22:26:44.700268Z",
     "iopub.status.busy": "2024-02-10T22:26:44.699968Z",
     "iopub.status.idle": "2024-02-10T23:13:35.866227Z",
     "shell.execute_reply": "2024-02-10T23:13:35.865286Z",
     "shell.execute_reply.started": "2024-02-10T22:26:44.700236Z"
    },
    "id": "x9-e4qVEZpgo",
    "outputId": "3528f7e1-5fdb-4653-aa0b-eb04795d464b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 3268/3268 [04:38<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.68937271651031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 5.276047459138943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 5.112479813095989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 5.0334168777617565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 4.986323413533709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 4.952393132440901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 4.922186558585126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 4.900054754796489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 4.878925438318287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 3268/3268 [04:41<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 4.853318162034454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:35.868000Z",
     "iopub.status.busy": "2024-02-10T23:13:35.867585Z",
     "iopub.status.idle": "2024-02-10T23:13:36.449101Z",
     "shell.execute_reply": "2024-02-10T23:13:36.448446Z",
     "shell.execute_reply.started": "2024-02-10T23:13:35.867962Z"
    },
    "id": "uJWNidupWMlc"
   },
   "outputs": [],
   "source": [
    "# saving the entire model\n",
    "torch.save(model.state_dict(), 'rnn_model.pth')\n",
    "\n",
    "# saving the vocabularies as well for future reference\n",
    "vocabularies = {\n",
    "    'input_vocab': input_vocab,\n",
    "    'output_vocab': output_vocab\n",
    "}\n",
    "\n",
    "with open('vocabularies.json', 'w') as vocab_file:\n",
    "    json.dump(vocabularies, vocab_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:36.450384Z",
     "iopub.status.busy": "2024-02-10T23:13:36.450045Z",
     "iopub.status.idle": "2024-02-10T23:13:36.892855Z",
     "shell.execute_reply": "2024-02-10T23:13:36.892219Z",
     "shell.execute_reply.started": "2024-02-10T23:13:36.450346Z"
    },
    "id": "QknT2OlyWTEC"
   },
   "outputs": [],
   "source": [
    "max_input_length = 65\n",
    "# loading the vocabularies\n",
    "with open('./vocabularies.json', 'r') as vocab_file:\n",
    "    loaded_vocabularies = json.load(vocab_file)\n",
    "\n",
    "input_vocab = loaded_vocabularies['input_vocab']\n",
    "output_vocab = loaded_vocabularies['output_vocab']\n",
    "\n",
    "# creating a new instance of the RNN model\n",
    "loaded_model = RNN(len(input_vocab), 256, len(output_vocab)).to(device)\n",
    "\n",
    "# loading the trained model weights\n",
    "map_location=torch.device('cpu')\n",
    "loaded_model.load_state_dict(torch.load('./rnn_model.pth'))\n",
    "loaded_model.eval()  # Setting the model to evaluation mode\n",
    "\n",
    "def predict(model, input_sequence, input_vocab, output_vocab):\n",
    "    # Preprocess and tokenize input_sequence\n",
    "    preprocessed_input = preprocess(input_sequence)\n",
    "    tokenized_input = word_tokenize(preprocessed_input)\n",
    "\n",
    "    # Numericalize input using the loaded vocabularies\n",
    "    numericalized_input = pad_sequence(tokenized_input, max_input_length, input_vocab)\n",
    "\n",
    "    # Convert numericalized input to PyTorch tensor\n",
    "    input_tensor = torch.tensor(numericalized_input).unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction using the loaded model\n",
    "    with torch.no_grad():\n",
    "        model_output = model(input_tensor)\n",
    "\n",
    "    # Process the model output\n",
    "    _, predicted_indices = torch.max(model_output, dim=2 )\n",
    "\n",
    "    # Convert predicted indices to words using the output vocabulary\n",
    "    predicted_words = [word for index in predicted_indices.squeeze().tolist() for word, idx in output_vocab.items() if idx == index]\n",
    "\n",
    "    # Join the words into a string (or use as needed)\n",
    "    processed_output = ' '.join(predicted_words)\n",
    "\n",
    "    return processed_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:36.894055Z",
     "iopub.status.busy": "2024-02-10T23:13:36.893738Z",
     "iopub.status.idle": "2024-02-10T23:13:37.015474Z",
     "shell.execute_reply": "2024-02-10T23:13:37.014749Z",
     "shell.execute_reply.started": "2024-02-10T23:13:36.894033Z"
    },
    "id": "t_9B0JxoWxp_",
    "outputId": "9e57cc5a-f972-4592-e900-05ef8dc1fe55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: luck is not everything that you may want to rely stumbled . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "# example usage:\n",
    "input_sentence = \"Luck isn't everything that you may wanna rely upon!!!\"\n",
    "predictions = predict(loaded_model, input_sentence, input_vocab, output_vocab)\n",
    "print(\"Predicted output:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:37.016869Z",
     "iopub.status.busy": "2024-02-10T23:13:37.016476Z",
     "iopub.status.idle": "2024-02-10T23:13:37.036338Z",
     "shell.execute_reply": "2024-02-10T23:13:37.035600Z",
     "shell.execute_reply.started": "2024-02-10T23:13:37.016844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luck is not everything that you may want to rely stumbled......................................................\n"
     ]
    }
   ],
   "source": [
    "predictions = preprocess(predictions)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:37.037551Z",
     "iopub.status.busy": "2024-02-10T23:13:37.037169Z",
     "iopub.status.idle": "2024-02-10T23:13:37.050227Z",
     "shell.execute_reply": "2024-02-10T23:13:37.049654Z",
     "shell.execute_reply.started": "2024-02-10T23:13:37.037524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luck is not everything that you may want to rely stumbled.\n"
     ]
    }
   ],
   "source": [
    "predictions = preprocess(predictions)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seMoRzzC7W7s"
   },
   "source": [
    "# Metrics Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing TERp and PINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:37.051889Z",
     "iopub.status.busy": "2024-02-10T23:13:37.051300Z",
     "iopub.status.idle": "2024-02-10T23:13:43.406230Z",
     "shell.execute_reply": "2024-02-10T23:13:43.405345Z",
     "shell.execute_reply.started": "2024-02-10T23:13:37.051851Z"
    },
    "id": "1dVY4RavDmN6",
    "outputId": "d3d13484-9f26-4da6-ea85-ca22ca282d59",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (1.26.3)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: nltk in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: sacrebleu in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: click in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: portalocker in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sacrebleu) (1.26.3)\n",
      "Requirement already satisfied: colorama in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sacrebleu) (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install nltk sacrebleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:43.408213Z",
     "iopub.status.busy": "2024-02-10T23:13:43.407642Z",
     "iopub.status.idle": "2024-02-10T23:13:46.459397Z",
     "shell.execute_reply": "2024-02-10T23:13:46.458565Z",
     "shell.execute_reply.started": "2024-02-10T23:13:43.408169Z"
    },
    "id": "eMFyxV7MDr5c",
    "outputId": "f6e5de8b-1795-4a9a-df6f-c1158d813f8e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 23:13:44.490798: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-10 23:13:44.537966: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-10 23:13:44.538001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-10 23:13:44.539525: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-10 23:13:44.550150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-10 23:13:45.908493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import numpy as np\n",
    "import json\n",
    "from transformers import EncoderDecoderModel\n",
    "import torchmetrics\n",
    "from datasets import Dataset\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import gc\n",
    "import torch\n",
    "import math\n",
    "import sacrebleu\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk import ngrams\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:46.461631Z",
     "iopub.status.busy": "2024-02-10T23:13:46.460778Z",
     "iopub.status.idle": "2024-02-10T23:13:46.474463Z",
     "shell.execute_reply": "2024-02-10T23:13:46.473615Z",
     "shell.execute_reply.started": "2024-02-10T23:13:46.461591Z"
    },
    "id": "TfxVHg31D8sN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Higher is better\n",
    "def calculate_terp(hypothesis: str, reference: str, phrase_table=list(), edit_costs=list()):\n",
    "    hypothesis_tokens = hypothesis.split()\n",
    "    reference_tokens = reference.split()\n",
    "\n",
    "    # TERp by Stem Matches, Synonym Matches, and Phrase Substitutions\n",
    "    stem_matches = calculate_stem_matches(hypothesis_tokens, reference_tokens)\n",
    "    synonym_matches = calculate_synonym_matches(hypothesis_tokens, reference_tokens)\n",
    "    phrase_substitutions = calculate_phrase_substitutions(hypothesis_tokens, reference_tokens, phrase_table, edit_costs)\n",
    "\n",
    "    # Calculate TERp score\n",
    "    terp_score = (stem_matches + synonym_matches + phrase_substitutions) / len(reference_tokens)\n",
    "\n",
    "    return terp_score\n",
    "\n",
    "def calculate_stem_matches(hypothesis_tokens, reference_tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stem_matches = sum(1 for hyp_token, ref_token in zip(hypothesis_tokens, reference_tokens)\n",
    "                      if stemmer.stem(hyp_token.lower()) == stemmer.stem(ref_token.lower()))\n",
    "    return stem_matches\n",
    "\n",
    "def calculate_synonym_matches(hypothesis_tokens, reference_tokens):\n",
    "    synonym_matches = sum(1 for hyp_token, ref_token in zip(hypothesis_tokens, reference_tokens)\n",
    "                          if are_synonyms(hyp_token.lower(), ref_token.lower()))\n",
    "    return synonym_matches\n",
    "\n",
    "def are_synonyms(word1, word2):\n",
    "    synsets1 = wordnet.synsets(word1)\n",
    "    synsets2 = wordnet.synsets(word2)\n",
    "\n",
    "    return any(set1.wup_similarity(set2) > 0.7 for set1 in synsets1 for set2 in synsets2)\n",
    "\n",
    "def calculate_phrase_substitutions(hypothesis_tokens, reference_tokens, phrase_table, edit_costs):\n",
    "    substitution_cost = 0\n",
    "\n",
    "    for i in range(len(hypothesis_tokens)):\n",
    "        for j in range(len(reference_tokens)):\n",
    "            if (hypothesis_tokens[i], reference_tokens[j]) in phrase_table:\n",
    "                # Retrieve paraphrase information from the phrase table\n",
    "                paraphrase_info = phrase_table[(hypothesis_tokens[i], reference_tokens[j])]\n",
    "\n",
    "                # Calculate the cost using the provided formula\n",
    "                cost = (\n",
    "                    edit_costs['w1'] +\n",
    "                    edit_costs['w2'] * paraphrase_info['edit'] * math.log(paraphrase_info['probability']) +\n",
    "                    edit_costs['w3'] * paraphrase_info['edit'] * paraphrase_info['probability'] +\n",
    "                    edit_costs['w4'] * paraphrase_info['edit']\n",
    "                )\n",
    "\n",
    "                # Ensure the substitution cost is not negative\n",
    "                substitution_cost += max(0, cost)\n",
    "\n",
    "    return substitution_cost\n",
    "\n",
    "def terp_alignment(hypothesis, reference, phrase_table=list(), edit_costs=list()):\n",
    "    alignment = []\n",
    "\n",
    "    for hyp_token, ref_token in zip(hypothesis.split(), reference.split()):\n",
    "        if hyp_token == ref_token:\n",
    "            alignment.append((hyp_token, ref_token, \"Exact Match\"))\n",
    "        else:\n",
    "            alignment.append((hyp_token, ref_token, \"Mismatch\"))\n",
    "\n",
    "    return alignment\n",
    "\n",
    "def calculate_pinc(hypothesis: str, reference: str, n: int):\n",
    "    hypothesis_split = hypothesis.split()\n",
    "    reference_split = reference.split()\n",
    "\n",
    "    hypothesis_ngrams = set(ngrams(hypothesis_split, n))\n",
    "    reference_ngrams = set(ngrams(reference_split, n))\n",
    "    new_ngrams = hypothesis_ngrams - reference_ngrams\n",
    "    pinc_score = len(new_ngrams) / len(hypothesis_ngrams)\n",
    "\n",
    "    return pinc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:46.475713Z",
     "iopub.status.busy": "2024-02-10T23:13:46.475395Z",
     "iopub.status.idle": "2024-02-10T23:13:48.063112Z",
     "shell.execute_reply": "2024-02-10T23:13:48.062272Z",
     "shell.execute_reply.started": "2024-02-10T23:13:46.475688Z"
    },
    "id": "DhIW79_LEprc",
    "outputId": "07bc90a6-3905-43cc-cd83-d758f1ab9b97",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERp Score: 1.6\n",
      "Alignment: [('This', 'This', 'Exact Match'), ('is', 'is', 'Exact Match'), ('an', 'an', 'Exact Match'), ('example', 'example', 'Exact Match'), ('sentence.', 'sentence.', 'Exact Match')]\n"
     ]
    }
   ],
   "source": [
    "# example usage:\n",
    "hypothesis_sentence = \"This is an example sentence.\"\n",
    "reference_sentence = \"This is an example sentence.\"\n",
    "\n",
    "# calculating TERp score\n",
    "terp_score = calculate_terp(hypothesis_sentence, reference_sentence)\n",
    "print(f\"TERp Score: {terp_score}\")\n",
    "\n",
    "# generating alignment\n",
    "alignment = terp_alignment(hypothesis_sentence, reference_sentence)\n",
    "print(\"Alignment:\", alignment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.064582Z",
     "iopub.status.busy": "2024-02-10T23:13:48.064191Z",
     "iopub.status.idle": "2024-02-10T23:13:48.068239Z",
     "shell.execute_reply": "2024-02-10T23:13:48.067627Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.064553Z"
    },
    "id": "LADXQx2vE0GL",
    "outputId": "19688f47-9f41-4098-c6ed-221a324f5648",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINC Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "pinc_score = calculate_pinc(hypothesis_sentence, reference_sentence, 2)\n",
    "print(f\"PINC Score: {pinc_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.069444Z",
     "iopub.status.busy": "2024-02-10T23:13:48.069118Z",
     "iopub.status.idle": "2024-02-10T23:13:48.074255Z",
     "shell.execute_reply": "2024-02-10T23:13:48.073563Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.069421Z"
    },
    "id": "643-PTYTE2vR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def terp(preds, refs):\n",
    "  scores = np.zeros(len(preds), dtype=float)\n",
    "  for i in range(len(preds)):\n",
    "    pred = preds[i]\n",
    "    ref = refs[i]\n",
    "    score = np.min(np.array(list(map(lambda x: calculate_terp(pred, x), ref))))\n",
    "    scores[i] = score\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.075674Z",
     "iopub.status.busy": "2024-02-10T23:13:48.075190Z",
     "iopub.status.idle": "2024-02-10T23:13:48.080163Z",
     "shell.execute_reply": "2024-02-10T23:13:48.079356Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.075646Z"
    },
    "id": "7KLK7J8hE5L7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pinc(preds, refs, n=2):\n",
    "  scores = np.zeros(len(preds), dtype=float)\n",
    "  for i in range(len(preds)):\n",
    "    pred = preds[i]\n",
    "    ref = refs[i]\n",
    "    score = np.min(np.array(list(map(lambda x: calculate_pinc(pred, x, n), ref))))\n",
    "    scores[i] = score\n",
    "\n",
    "  return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.081276Z",
     "iopub.status.busy": "2024-02-10T23:13:48.081021Z",
     "iopub.status.idle": "2024-02-10T23:13:48.084783Z",
     "shell.execute_reply": "2024-02-10T23:13:48.084049Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.081255Z"
    },
    "id": "vVcvPL8-KiU4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_files={\n",
    "    \"val\":\"./GYAFC_Corpus/data_val.json\",\n",
    "    \"test\":\"./GYAFC_Corpus/data_test.json\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.085857Z",
     "iopub.status.busy": "2024-02-10T23:13:48.085555Z",
     "iopub.status.idle": "2024-02-10T23:13:48.125980Z",
     "shell.execute_reply": "2024-02-10T23:13:48.125375Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.085832Z"
    },
    "id": "V038BzKoKk9R",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from the validation set\n",
    "with open(data_files[\"val\"], 'r') as file:\n",
    "    val_data = json.load(file)\n",
    "\n",
    "# Load data from the test set\n",
    "with open(data_files[\"test\"], 'r') as file:\n",
    "    test_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.127420Z",
     "iopub.status.busy": "2024-02-10T23:13:48.127020Z",
     "iopub.status.idle": "2024-02-10T23:13:48.147772Z",
     "shell.execute_reply": "2024-02-10T23:13:48.147015Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.127381Z"
    },
    "id": "ywmrCVsHNJTT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate informal, formal references for evaluation\n",
    "val_informal = [item['transformation']['informal'] for item in val_data]\n",
    "val_formal_refs = [\n",
    "    [item['transformation'][f'formal.ref{i}'] for i in range(4)] for item in val_data\n",
    "]\n",
    "\n",
    "test_informal = [item['transformation']['informal'] for item in test_data]\n",
    "test_formal_refs = [\n",
    "    [item['transformation'][f'formal.ref{i}'] for i in range(4)] for item in test_data\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.149279Z",
     "iopub.status.busy": "2024-02-10T23:13:48.148881Z",
     "iopub.status.idle": "2024-02-10T23:13:48.153626Z",
     "shell.execute_reply": "2024-02-10T23:13:48.152874Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.149244Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2748\n",
      "5665\n"
     ]
    }
   ],
   "source": [
    "print(len(test_formal_refs))\n",
    "print(len(val_formal_refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:13:48.154772Z",
     "iopub.status.busy": "2024-02-10T23:13:48.154488Z",
     "iopub.status.idle": "2024-02-10T23:31:03.231556Z",
     "shell.execute_reply": "2024-02-10T23:31:03.230635Z",
     "shell.execute_reply.started": "2024-02-10T23:13:48.154751Z"
    },
    "id": "mGYUY-NxNoqj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are under eighteen you have a I Problem.......................................................\n",
      ", So what if it is a rebound relationship for both of you?...................................................\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_preds = [preprocess(predict(model, input_seq, input_vocab, output_vocab)) for input_seq in val_informal]\n",
    "print(val_preds[0])\n",
    "test_preds = [preprocess(predict(model, input_seq, input_vocab, output_vocab)) for input_seq in test_informal]\n",
    "print(test_preds[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T23:31:03.233202Z",
     "iopub.status.busy": "2024-02-10T23:31:03.232784Z",
     "iopub.status.idle": "2024-02-10T23:36:37.957870Z",
     "shell.execute_reply": "2024-02-10T23:36:37.956993Z",
     "shell.execute_reply.started": "2024-02-10T23:31:03.233163Z"
    },
    "id": "nk73WLXpNuQ9",
    "outputId": "fc9510c0-b609-4b59-ac72-e784125bdde1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TERp Score on Validation Set: 0.12609746638995742\n",
      "Average PINC Score on Validation Set (n=2): 0.5607699082789491\n",
      "Average TERp Score on Test Set: 0.13361001705850603\n",
      "Average PINC Score on Test Set (n=2): 0.544418614460787\n"
     ]
    }
   ],
   "source": [
    "# Evaluate TERp score on validation set\n",
    "val_terp_score = terp(val_preds, val_formal_refs)\n",
    "print(f\"Average TERp Score on Validation Set: {val_terp_score}\")\n",
    "# Evaluate PINC score on validation set\n",
    "val_pinc_score = pinc(val_preds, val_formal_refs, n=2)\n",
    "print(f\"Average PINC Score on Validation Set (n=2): {val_pinc_score}\")\n",
    "\n",
    "# Evaluate TERp score on test set\n",
    "test_terp_score = terp(test_preds, test_formal_refs)\n",
    "print(f\"Average TERp Score on Test Set: {test_terp_score}\")\n",
    "# Evaluate PINC score on validation set\n",
    "test_pinc_score = pinc(test_preds, test_formal_refs, n=2)\n",
    "print(f\"Average PINC Score on Test Set (n=2): {test_pinc_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing BLEU and TER from torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:36:37.959333Z",
     "iopub.status.busy": "2024-02-10T23:36:37.958919Z",
     "iopub.status.idle": "2024-02-10T23:36:41.147117Z",
     "shell.execute_reply": "2024-02-10T23:36:41.146267Z",
     "shell.execute_reply.started": "2024-02-10T23:36:37.959308Z"
    },
    "id": "2Ul0FVN2Peh7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (1.26.3)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torchmetrics) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:36:41.148718Z",
     "iopub.status.busy": "2024-02-10T23:36:41.148312Z",
     "iopub.status.idle": "2024-02-10T23:37:21.037755Z",
     "shell.execute_reply": "2024-02-10T23:37:21.036801Z",
     "shell.execute_reply.started": "2024-02-10T23:36:41.148690Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `BLEUScore` from `torchmetrics` was deprecated and will be removed in 2.0. Import `BLEUScore` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score on Validation Set: 0.4055926501750946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `TranslationEditRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `TranslationEditRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TER Score on Validation Set: 0.4402236342430115\n",
      "Average BLEU Score on Test Set: 0.42151957750320435\n",
      "Average TER Score on Test Set: 0.4148395359516144\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics.text import BLEUScore\n",
    "from torchmetrics.text import TranslationEditRate\n",
    "\n",
    "def calculate_bleu(hypothesis, reference):\n",
    "    bleu_metric = torchmetrics.BLEUScore()\n",
    "    return bleu_metric(hypothesis, reference)\n",
    "\n",
    "def calculate_ter(hypothesis, reference):\n",
    "    ter_metric = torchmetrics.TranslationEditRate()\n",
    "    return ter_metric(hypothesis, reference)\n",
    "\n",
    "# Example usage:\n",
    "hypothesis_sentence = \"This is an example sentence.\"\n",
    "reference_sentence = \"This is an example sentence.\"\n",
    "\n",
    "# Calculate BLEU score on Validation Set\n",
    "bleu_score = calculate_bleu(val_preds, val_formal_refs)\n",
    "print(f\"Average BLEU Score on Validation Set: {bleu_score}\")\n",
    "# Calculate TER score on Validation Set\n",
    "ter_score = calculate_ter(val_preds, val_formal_refs)\n",
    "print(f\"Average TER Score on Validation Set: {ter_score}\")\n",
    "\n",
    "# Calculate BLEU score on Test Set\n",
    "bleu_score = calculate_bleu(test_preds, test_formal_refs)\n",
    "print(f\"Average BLEU Score on Test Set: {bleu_score}\")\n",
    "# Calculate TER score on Test Set\n",
    "ter_score = calculate_ter(test_preds, test_formal_refs)\n",
    "print(f\"Average TER Score on Test Set: {ter_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
