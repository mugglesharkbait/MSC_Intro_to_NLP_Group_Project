{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmdXVBAWGpsM"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeY28k58DG8T",
        "outputId": "b1f97078-6c2e-4b96-f2c7-a76f0157cfd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-kDQGv4DMWY",
        "outputId": "efc96dfb-8a93-4382-d427-c58bc0e701d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MSC_Intro_to_NLP_Group_Project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/MSC_Intro_to_NLP_Group_Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf8V8EEnGpsO",
        "outputId": "0d598d87-2c6e-4056-8692-02f26b131b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install 'transformers[torch]'\n",
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "dsTI9k5EGpsP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "za2IufRcGpsQ"
      },
      "outputs": [],
      "source": [
        "# Load the preprocessed data from the JSON file\n",
        "data_files={\n",
        "    \"train\":\"data_train_rule_based_preprocess.json\",\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZVuX7tQGpsQ",
        "outputId": "f5be656a-33c2-4462-add5-6a4938ade807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['transformation', 'id', 'topic'],\n",
            "        num_rows: 104562\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VHVZE9FqGpsQ"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UmUg7stiGpsQ"
      },
      "outputs": [],
      "source": [
        "# Tokenize the informal sentences\n",
        "def preprocess_function(examples, input_field=\"informal\", target_field=\"formal.ref0\"):\n",
        "    inputs = [ex[input_field] for ex in examples[\"transformation\"]]\n",
        "    targets = [ex[target_field] for ex in examples[\"transformation\"]]\n",
        "\n",
        "    new_examples = tokenizer(\n",
        "        inputs, text_target=targets, max_length=64, truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    return new_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uvuG0IrXGpsR"
      },
      "outputs": [],
      "source": [
        "def create_multi_ref_dataset(dataset):\n",
        "  for i, target_field in enumerate(['formal.ref0', 'formal.ref1', 'formal.ref2', 'formal.ref3']):\n",
        "    new_dataset = preprocess_function(dataset, 'informal', target_field)\n",
        "    dataset = dataset.add_column(f'labels_{i}', new_dataset['labels'])\n",
        "    if i == 0:\n",
        "      dataset = dataset.add_column('input_ids', new_dataset['input_ids'])\n",
        "      dataset = dataset.add_column('token_type_ids', new_dataset['token_type_ids'])\n",
        "      dataset = dataset.add_column('attention_mask', new_dataset['attention_mask'])\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ty2c8kBNGpsR"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train'].map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvaqW1B5GpsR",
        "outputId": "fbd65e13-5f57-4679-b15d-339d09497b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Sure',\n",
              " ',',\n",
              " 'it',\n",
              " \"'\",\n",
              " 's',\n",
              " 'ok',\n",
              " ',',\n",
              " 'but',\n",
              " 'I',\n",
              " 'always',\n",
              " 'have',\n",
              " 'let',\n",
              " 'the',\n",
              " 'guy',\n",
              " 'ask',\n",
              " 'me',\n",
              " '.',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(train_dataset['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OlPng_0YA-ry"
      },
      "outputs": [],
      "source": [
        "# # splitting the train dataset to use only 10% of it\n",
        "# train_dataset = train_dataset.train_test_split(test_size=0.9, shuffle=True, seed=42)\n",
        "# train_dataset = train_dataset['train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB25faOAGpsR"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGjL-PNdA-ry",
        "outputId": "d06ba9e9-f84e-48d3-9503-281266cd30cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "# Using the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "gpu_name = torch.cuda.get_device_name(device)\n",
        "print(gpu_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaP22qU2GpsR"
      },
      "source": [
        "# RNN Try 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sPAeeNqbGpsR"
      },
      "outputs": [],
      "source": [
        "# RNN first try\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.rnn(x)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "q2_8RWpJGpsS"
      },
      "outputs": [],
      "source": [
        "# class Seq2SeqRNN(nn.Module):\n",
        "#     def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
        "#         super(Seq2SeqRNN, self).__init__()\n",
        "#         self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "#         self.rnn = nn.RNN(embedding_size, hidden_size)\n",
        "#         self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, input_seq, hidden=None):\n",
        "#         embedded = self.embedding(input_seq)\n",
        "#         output, hidden = self.rnn(embedded, hidden)\n",
        "#         output = self.fc(output)\n",
        "#         return output, hidden\n",
        "\n",
        "# # Define hyperparameters\n",
        "# input_size = len(tokenizer.get_vocab())\n",
        "# embedding_size = 256\n",
        "# hidden_size = 512\n",
        "# output_size = len(tokenizer.get_vocab())\n",
        "\n",
        "# # Instantiate the model\n",
        "# model = Seq2SeqRNN(input_size, embedding_size, hidden_size, output_size)\n",
        "\n",
        "# # Define loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# # Training loop\n",
        "# num_epochs = 1\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     for batch in train_dataset:\n",
        "#         inputs = torch.tensor(batch[\"input_ids\"]).to(device)\n",
        "#         targets = torch.tensor(batch[\"labels\"]).to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         output, _ = model(inputs)\n",
        "\n",
        "#         # Reshape the output to be 2D (batch_size * sequence_length, vocab_size)\n",
        "#         output = output.view(-1, output_size)\n",
        "\n",
        "#         loss = criterion(output, targets.view(-1))\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Print the loss for monitoring training progress\n",
        "#         print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "# # Save the trained model\n",
        "# torch.save(model.state_dict(), \"seq2seq_rnn_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Xdzv3JhxXn6i"
      },
      "outputs": [],
      "source": [
        "# # Load the model\n",
        "# model = Seq2SeqRNN(input_size, embedding_size, hidden_size, output_size)\n",
        "# model.load_state_dict(torch.load(\"seq2seq_rnn_model.pth\"))\n",
        "# model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# # Define the input sequence\n",
        "# input_seq = torch.tensor(tokenizer.encode(\"Yo! Sidd, what's up!!!\")).unsqueeze(0)\n",
        "\n",
        "# # Predict the output\n",
        "# output, _ = model(input_seq)\n",
        "# output = torch.argmax(output, dim=2)  # Get the most probable next token\n",
        "\n",
        "# # Decode the output\n",
        "# decoded_output = tokenizer.decode(output[0])\n",
        "\n",
        "# print(decoded_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNVqWd6wlkUP"
      },
      "source": [
        "## RNN Try 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "e9aLRTQ6XrKz"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.lstm(embedded)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7lucLENGaon4"
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# # choosing GPU\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Loading preprocessed data in train_dataset\n",
        "# input_ids = torch.tensor(train_dataset['input_ids']).to(device)\n",
        "# labels_0 = torch.tensor(train_dataset['labels']).to(device)\n",
        "\n",
        "# # Define your model\n",
        "# input_size = len(tokenizer.get_vocab())\n",
        "# print(\"||\" * 10)\n",
        "# print(input_size)\n",
        "# print(\"||\" * 10)\n",
        "# hidden_size = 512\n",
        "# output_size = len(tokenizer.get_vocab())\n",
        "# # output_size = 512\n",
        "\n",
        "# model = RNNModel(input_size, hidden_size, output_size)\n",
        "# model.to(device)\n",
        "\n",
        "# # Define your loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# # Train the model\n",
        "# num_epochs = 5\n",
        "# batch_size = 32\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     for i in range(0, len(input_ids), batch_size):\n",
        "#         inputs = input_ids[i:i+batch_size]\n",
        "#         targets = labels_0[i:i+batch_size]\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs.view(-1, output_size), targets.view(-1))\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         if (i // batch_size) % 10 == 0:\n",
        "#             print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i // batch_size}/{len(input_ids) // batch_size}], Loss: {loss.item()}')\n",
        "\n",
        "# # Save the trained model\n",
        "# torch.save(model.state_dict(), \"seq2seq_rnn_model.pth\")\n",
        "# print('Training finished!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "O-eJQxa7hD6P"
      },
      "outputs": [],
      "source": [
        "# # Load the model\n",
        "# loaded_model = RNNModel(input_size, hidden_size, output_size)\n",
        "# loaded_model.load_state_dict(torch.load('seq2seq_rnn_model.pth'))\n",
        "# loaded_model.eval()  # Set the model to evaluation mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "RU07oV3nmPjS"
      },
      "outputs": [],
      "source": [
        "# def preprocess_unseen_data(unseen_data, tokenizer):\n",
        "#     inputs = tokenizer(unseen_data, return_tensors='pt', max_length=64, truncation=True, padding=\"max_length\")\n",
        "#     return inputs\n",
        "\n",
        "# def predict(model, input_ids):\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(input_ids)\n",
        "#     return outputs\n",
        "\n",
        "# def decode_predictions(outputs, tokenizer):\n",
        "#     predicted_ids = torch.argmax(outputs, dim=-1)\n",
        "#     predicted_text = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "#     return predicted_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "W_afZRcmnH-Y"
      },
      "outputs": [],
      "source": [
        "# unseen_data = [\"Here's the data that needs to be checked!!!\"]\n",
        "\n",
        "# # Preprocess unseen data\n",
        "# unseen_inputs = preprocess_unseen_data(unseen_data, tokenizer)\n",
        "\n",
        "# # Make predictions\n",
        "# predictions = predict(loaded_model, unseen_inputs['input_ids'])\n",
        "\n",
        "# # Decode predictions\n",
        "# decoded_predictions = decode_predictions(predictions, tokenizer)\n",
        "\n",
        "# # Print the results\n",
        "# for input_text, output_text in zip(unseen_data, decoded_predictions):\n",
        "#     print(f'Input: {input_text}')\n",
        "#     print(f'Predicted Output: {output_text}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J4oN5xzv76y"
      },
      "source": [
        "## RNN Try 3 with encoder decoder arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ztCQjaoAnRLx"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_size, hidden_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.rnn = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_token, hidden):\n",
        "        embedded = self.embedding(input_token.unsqueeze(1))\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        output = self.fc(output.squeeze(1))\n",
        "        return output, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src_seq, trg_seq):\n",
        "        batch_size = src_seq.shape[0]\n",
        "        trg_len = trg_seq.shape[1]\n",
        "        trg_vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(src_seq.device)\n",
        "\n",
        "        hidden = self.encoder(src_seq)\n",
        "\n",
        "        input_token = trg_seq[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input_token, hidden)\n",
        "            outputs[:, t] = output\n",
        "            input_token = output.argmax(1)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rgaIaEn4sQwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd8a0ec-1a43-493a-e295-765afadd567b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [0/3267], Loss: 10.26727294921875\n",
            "Epoch [1/1], Step [10/3267], Loss: 2.4065234661102295\n",
            "Epoch [1/1], Step [20/3267], Loss: 1.5702769756317139\n",
            "Epoch [1/1], Step [30/3267], Loss: 1.6176707744598389\n",
            "Epoch [1/1], Step [40/3267], Loss: 1.6567312479019165\n",
            "Epoch [1/1], Step [50/3267], Loss: 1.6792460680007935\n",
            "Epoch [1/1], Step [60/3267], Loss: 1.8667702674865723\n",
            "Epoch [1/1], Step [70/3267], Loss: 1.692054271697998\n",
            "Epoch [1/1], Step [80/3267], Loss: 1.7448334693908691\n",
            "Epoch [1/1], Step [90/3267], Loss: 1.9046194553375244\n",
            "Epoch [1/1], Step [100/3267], Loss: 1.9233150482177734\n",
            "Epoch [1/1], Step [110/3267], Loss: 1.6469289064407349\n",
            "Epoch [1/1], Step [120/3267], Loss: 1.6849910020828247\n",
            "Epoch [1/1], Step [130/3267], Loss: 1.901947259902954\n",
            "Epoch [1/1], Step [140/3267], Loss: 1.5244415998458862\n",
            "Epoch [1/1], Step [150/3267], Loss: 1.723103642463684\n",
            "Epoch [1/1], Step [160/3267], Loss: 1.85185706615448\n",
            "Epoch [1/1], Step [170/3267], Loss: 1.59792959690094\n",
            "Epoch [1/1], Step [180/3267], Loss: 1.5638830661773682\n",
            "Epoch [1/1], Step [190/3267], Loss: 1.5713096857070923\n",
            "Epoch [1/1], Step [200/3267], Loss: 1.537764072418213\n",
            "Epoch [1/1], Step [210/3267], Loss: 1.5307728052139282\n",
            "Epoch [1/1], Step [220/3267], Loss: 1.6632766723632812\n",
            "Epoch [1/1], Step [230/3267], Loss: 1.499264121055603\n",
            "Epoch [1/1], Step [240/3267], Loss: 1.5261064767837524\n",
            "Epoch [1/1], Step [250/3267], Loss: 1.7768131494522095\n",
            "Epoch [1/1], Step [260/3267], Loss: 1.7184993028640747\n",
            "Epoch [1/1], Step [270/3267], Loss: 1.7876452207565308\n",
            "Epoch [1/1], Step [280/3267], Loss: 1.7870738506317139\n",
            "Epoch [1/1], Step [290/3267], Loss: 2.1251070499420166\n",
            "Epoch [1/1], Step [300/3267], Loss: 1.8265811204910278\n",
            "Epoch [1/1], Step [310/3267], Loss: 1.5645147562026978\n",
            "Epoch [1/1], Step [320/3267], Loss: 1.9469424486160278\n",
            "Epoch [1/1], Step [330/3267], Loss: 1.6368886232376099\n",
            "Epoch [1/1], Step [340/3267], Loss: 1.411929965019226\n",
            "Epoch [1/1], Step [350/3267], Loss: 1.7701139450073242\n",
            "Epoch [1/1], Step [360/3267], Loss: 1.859552025794983\n",
            "Epoch [1/1], Step [370/3267], Loss: 1.6538970470428467\n",
            "Epoch [1/1], Step [380/3267], Loss: 1.6857726573944092\n",
            "Epoch [1/1], Step [390/3267], Loss: 1.433974027633667\n",
            "Epoch [1/1], Step [400/3267], Loss: 1.7676832675933838\n",
            "Epoch [1/1], Step [410/3267], Loss: 1.5741406679153442\n",
            "Epoch [1/1], Step [420/3267], Loss: 1.5700201988220215\n",
            "Epoch [1/1], Step [430/3267], Loss: 1.4562727212905884\n",
            "Epoch [1/1], Step [440/3267], Loss: 1.4967362880706787\n",
            "Epoch [1/1], Step [450/3267], Loss: 1.4490060806274414\n",
            "Epoch [1/1], Step [460/3267], Loss: 1.5491793155670166\n",
            "Epoch [1/1], Step [470/3267], Loss: 1.8170408010482788\n",
            "Epoch [1/1], Step [480/3267], Loss: 1.5901241302490234\n",
            "Epoch [1/1], Step [490/3267], Loss: 1.3885483741760254\n",
            "Epoch [1/1], Step [500/3267], Loss: 1.6350425481796265\n",
            "Epoch [1/1], Step [510/3267], Loss: 1.403074026107788\n",
            "Epoch [1/1], Step [520/3267], Loss: 1.4073231220245361\n",
            "Epoch [1/1], Step [530/3267], Loss: 1.4836479425430298\n",
            "Epoch [1/1], Step [540/3267], Loss: 1.4642717838287354\n",
            "Epoch [1/1], Step [550/3267], Loss: 1.7083103656768799\n",
            "Epoch [1/1], Step [560/3267], Loss: 1.4359829425811768\n",
            "Epoch [1/1], Step [570/3267], Loss: 1.4625211954116821\n",
            "Epoch [1/1], Step [580/3267], Loss: 1.515126347541809\n",
            "Epoch [1/1], Step [590/3267], Loss: 1.7288405895233154\n",
            "Epoch [1/1], Step [600/3267], Loss: 1.5033663511276245\n",
            "Epoch [1/1], Step [610/3267], Loss: 1.7495383024215698\n",
            "Epoch [1/1], Step [620/3267], Loss: 1.532293677330017\n",
            "Epoch [1/1], Step [630/3267], Loss: 1.4693942070007324\n",
            "Epoch [1/1], Step [640/3267], Loss: 1.718302607536316\n",
            "Epoch [1/1], Step [650/3267], Loss: 1.5769522190093994\n",
            "Epoch [1/1], Step [660/3267], Loss: 1.54739511013031\n",
            "Epoch [1/1], Step [670/3267], Loss: 1.7418204545974731\n",
            "Epoch [1/1], Step [680/3267], Loss: 1.6408343315124512\n",
            "Epoch [1/1], Step [690/3267], Loss: 1.4003329277038574\n",
            "Epoch [1/1], Step [700/3267], Loss: 1.4874128103256226\n",
            "Epoch [1/1], Step [710/3267], Loss: 1.5840744972229004\n",
            "Epoch [1/1], Step [720/3267], Loss: 1.604894757270813\n",
            "Epoch [1/1], Step [730/3267], Loss: 1.4943524599075317\n",
            "Epoch [1/1], Step [740/3267], Loss: 1.6120156049728394\n",
            "Epoch [1/1], Step [750/3267], Loss: 1.7569725513458252\n",
            "Epoch [1/1], Step [760/3267], Loss: 1.3183858394622803\n",
            "Epoch [1/1], Step [770/3267], Loss: 1.571770429611206\n",
            "Epoch [1/1], Step [780/3267], Loss: 1.6113495826721191\n",
            "Epoch [1/1], Step [790/3267], Loss: 1.3852862119674683\n",
            "Epoch [1/1], Step [800/3267], Loss: 1.262463092803955\n",
            "Epoch [1/1], Step [810/3267], Loss: 1.3942850828170776\n",
            "Epoch [1/1], Step [820/3267], Loss: 1.4610519409179688\n",
            "Epoch [1/1], Step [830/3267], Loss: 1.4378515481948853\n",
            "Epoch [1/1], Step [840/3267], Loss: 1.516492247581482\n",
            "Epoch [1/1], Step [850/3267], Loss: 1.2937190532684326\n",
            "Epoch [1/1], Step [860/3267], Loss: 1.3241567611694336\n",
            "Epoch [1/1], Step [870/3267], Loss: 1.5545138120651245\n",
            "Epoch [1/1], Step [880/3267], Loss: 1.3942753076553345\n",
            "Epoch [1/1], Step [890/3267], Loss: 1.5093233585357666\n",
            "Epoch [1/1], Step [900/3267], Loss: 1.6066358089447021\n",
            "Epoch [1/1], Step [910/3267], Loss: 1.489793300628662\n",
            "Epoch [1/1], Step [920/3267], Loss: 1.5158475637435913\n",
            "Epoch [1/1], Step [930/3267], Loss: 1.6191459894180298\n",
            "Epoch [1/1], Step [940/3267], Loss: 1.5446429252624512\n",
            "Epoch [1/1], Step [950/3267], Loss: 1.7180192470550537\n",
            "Epoch [1/1], Step [960/3267], Loss: 1.6260480880737305\n",
            "Epoch [1/1], Step [970/3267], Loss: 1.6089330911636353\n",
            "Epoch [1/1], Step [980/3267], Loss: 1.2591955661773682\n",
            "Epoch [1/1], Step [990/3267], Loss: 1.2979204654693604\n",
            "Epoch [1/1], Step [1000/3267], Loss: 1.646740198135376\n",
            "Epoch [1/1], Step [1010/3267], Loss: 1.4202032089233398\n",
            "Epoch [1/1], Step [1020/3267], Loss: 1.5276237726211548\n",
            "Epoch [1/1], Step [1030/3267], Loss: 1.2895339727401733\n",
            "Epoch [1/1], Step [1040/3267], Loss: 1.560731291770935\n",
            "Epoch [1/1], Step [1050/3267], Loss: 1.3834033012390137\n",
            "Epoch [1/1], Step [1060/3267], Loss: 1.5515776872634888\n",
            "Epoch [1/1], Step [1070/3267], Loss: 1.7917369604110718\n",
            "Epoch [1/1], Step [1080/3267], Loss: 1.3682692050933838\n",
            "Epoch [1/1], Step [1090/3267], Loss: 1.3934226036071777\n",
            "Epoch [1/1], Step [1100/3267], Loss: 1.328309178352356\n",
            "Epoch [1/1], Step [1110/3267], Loss: 1.4788624048233032\n",
            "Epoch [1/1], Step [1120/3267], Loss: 1.7234225273132324\n",
            "Epoch [1/1], Step [1130/3267], Loss: 1.2449491024017334\n",
            "Epoch [1/1], Step [1140/3267], Loss: 1.3775943517684937\n",
            "Epoch [1/1], Step [1150/3267], Loss: 1.4273611307144165\n",
            "Epoch [1/1], Step [1160/3267], Loss: 1.5737699270248413\n",
            "Epoch [1/1], Step [1170/3267], Loss: 1.4011635780334473\n",
            "Epoch [1/1], Step [1180/3267], Loss: 1.777043342590332\n",
            "Epoch [1/1], Step [1190/3267], Loss: 1.4022583961486816\n",
            "Epoch [1/1], Step [1200/3267], Loss: 1.3503040075302124\n",
            "Epoch [1/1], Step [1210/3267], Loss: 1.447596549987793\n",
            "Epoch [1/1], Step [1220/3267], Loss: 1.5638365745544434\n",
            "Epoch [1/1], Step [1230/3267], Loss: 1.442598581314087\n",
            "Epoch [1/1], Step [1240/3267], Loss: 1.355872392654419\n",
            "Epoch [1/1], Step [1250/3267], Loss: 1.4330142736434937\n",
            "Epoch [1/1], Step [1260/3267], Loss: 1.5703107118606567\n",
            "Epoch [1/1], Step [1270/3267], Loss: 1.311669945716858\n",
            "Epoch [1/1], Step [1280/3267], Loss: 1.4512749910354614\n",
            "Epoch [1/1], Step [1290/3267], Loss: 1.6207557916641235\n",
            "Epoch [1/1], Step [1300/3267], Loss: 1.364730954170227\n",
            "Epoch [1/1], Step [1310/3267], Loss: 1.4610896110534668\n",
            "Epoch [1/1], Step [1320/3267], Loss: 1.540859341621399\n",
            "Epoch [1/1], Step [1330/3267], Loss: 1.4953877925872803\n",
            "Epoch [1/1], Step [1340/3267], Loss: 1.4343799352645874\n",
            "Epoch [1/1], Step [1350/3267], Loss: 1.531740665435791\n",
            "Epoch [1/1], Step [1360/3267], Loss: 1.4176661968231201\n",
            "Epoch [1/1], Step [1370/3267], Loss: 1.2900062799453735\n",
            "Epoch [1/1], Step [1380/3267], Loss: 1.6299794912338257\n",
            "Epoch [1/1], Step [1390/3267], Loss: 1.6476114988327026\n",
            "Epoch [1/1], Step [1400/3267], Loss: 1.460312843322754\n",
            "Epoch [1/1], Step [1410/3267], Loss: 1.5598304271697998\n",
            "Epoch [1/1], Step [1420/3267], Loss: 1.3523434400558472\n",
            "Epoch [1/1], Step [1430/3267], Loss: 1.4294602870941162\n",
            "Epoch [1/1], Step [1440/3267], Loss: 1.3569552898406982\n",
            "Epoch [1/1], Step [1450/3267], Loss: 1.662384033203125\n",
            "Epoch [1/1], Step [1460/3267], Loss: 1.5743881464004517\n",
            "Epoch [1/1], Step [1470/3267], Loss: 1.1463006734848022\n",
            "Epoch [1/1], Step [1480/3267], Loss: 1.3598517179489136\n",
            "Epoch [1/1], Step [1490/3267], Loss: 1.2520216703414917\n",
            "Epoch [1/1], Step [1500/3267], Loss: 1.3328559398651123\n",
            "Epoch [1/1], Step [1510/3267], Loss: 1.427490472793579\n",
            "Epoch [1/1], Step [1520/3267], Loss: 1.255005955696106\n",
            "Epoch [1/1], Step [1530/3267], Loss: 1.4262840747833252\n",
            "Epoch [1/1], Step [1540/3267], Loss: 1.420157790184021\n",
            "Epoch [1/1], Step [1550/3267], Loss: 1.2360036373138428\n",
            "Epoch [1/1], Step [1560/3267], Loss: 1.5177867412567139\n",
            "Epoch [1/1], Step [1570/3267], Loss: 1.4060529470443726\n",
            "Epoch [1/1], Step [1580/3267], Loss: 1.314359188079834\n",
            "Epoch [1/1], Step [1590/3267], Loss: 1.2782037258148193\n",
            "Epoch [1/1], Step [1600/3267], Loss: 1.5135525465011597\n",
            "Epoch [1/1], Step [1610/3267], Loss: 1.3776763677597046\n",
            "Epoch [1/1], Step [1620/3267], Loss: 1.6601577997207642\n",
            "Epoch [1/1], Step [1630/3267], Loss: 1.557506799697876\n",
            "Epoch [1/1], Step [1640/3267], Loss: 1.645731806755066\n",
            "Epoch [1/1], Step [1650/3267], Loss: 2.0602316856384277\n",
            "Epoch [1/1], Step [1660/3267], Loss: 1.6479331254959106\n",
            "Epoch [1/1], Step [1670/3267], Loss: 1.902805209159851\n",
            "Epoch [1/1], Step [1680/3267], Loss: 1.5239202976226807\n",
            "Epoch [1/1], Step [1690/3267], Loss: 1.790793538093567\n",
            "Epoch [1/1], Step [1700/3267], Loss: 1.5080140829086304\n",
            "Epoch [1/1], Step [1710/3267], Loss: 1.746518611907959\n",
            "Epoch [1/1], Step [1720/3267], Loss: 1.5599979162216187\n",
            "Epoch [1/1], Step [1730/3267], Loss: 1.740064024925232\n",
            "Epoch [1/1], Step [1740/3267], Loss: 1.6031948328018188\n",
            "Epoch [1/1], Step [1750/3267], Loss: 1.47238028049469\n",
            "Epoch [1/1], Step [1760/3267], Loss: 2.118265151977539\n",
            "Epoch [1/1], Step [1770/3267], Loss: 1.5419758558273315\n",
            "Epoch [1/1], Step [1780/3267], Loss: 1.759759783744812\n",
            "Epoch [1/1], Step [1790/3267], Loss: 1.6275535821914673\n",
            "Epoch [1/1], Step [1800/3267], Loss: 1.5030889511108398\n",
            "Epoch [1/1], Step [1810/3267], Loss: 1.4955607652664185\n",
            "Epoch [1/1], Step [1820/3267], Loss: 1.647206425666809\n",
            "Epoch [1/1], Step [1830/3267], Loss: 1.6850342750549316\n",
            "Epoch [1/1], Step [1840/3267], Loss: 1.631413221359253\n",
            "Epoch [1/1], Step [1850/3267], Loss: 1.8730864524841309\n",
            "Epoch [1/1], Step [1860/3267], Loss: 1.5621694326400757\n",
            "Epoch [1/1], Step [1870/3267], Loss: 1.6181567907333374\n",
            "Epoch [1/1], Step [1880/3267], Loss: 1.6362965106964111\n",
            "Epoch [1/1], Step [1890/3267], Loss: 1.6269009113311768\n",
            "Epoch [1/1], Step [1900/3267], Loss: 1.524868130683899\n",
            "Epoch [1/1], Step [1910/3267], Loss: 1.533100962638855\n",
            "Epoch [1/1], Step [1920/3267], Loss: 1.4507454633712769\n",
            "Epoch [1/1], Step [1930/3267], Loss: 1.7557942867279053\n",
            "Epoch [1/1], Step [1940/3267], Loss: 1.572627067565918\n",
            "Epoch [1/1], Step [1950/3267], Loss: 1.6302376985549927\n",
            "Epoch [1/1], Step [1960/3267], Loss: 1.3978923559188843\n",
            "Epoch [1/1], Step [1970/3267], Loss: 1.5000090599060059\n",
            "Epoch [1/1], Step [1980/3267], Loss: 1.4114750623703003\n",
            "Epoch [1/1], Step [1990/3267], Loss: 1.7885042428970337\n",
            "Epoch [1/1], Step [2000/3267], Loss: 1.8296691179275513\n",
            "Epoch [1/1], Step [2010/3267], Loss: 1.4433972835540771\n",
            "Epoch [1/1], Step [2020/3267], Loss: 1.810349941253662\n",
            "Epoch [1/1], Step [2030/3267], Loss: 1.463240146636963\n",
            "Epoch [1/1], Step [2040/3267], Loss: 1.8640527725219727\n",
            "Epoch [1/1], Step [2050/3267], Loss: 1.5453630685806274\n",
            "Epoch [1/1], Step [2060/3267], Loss: 1.3423579931259155\n",
            "Epoch [1/1], Step [2070/3267], Loss: 1.3670680522918701\n",
            "Epoch [1/1], Step [2080/3267], Loss: 1.5943191051483154\n",
            "Epoch [1/1], Step [2090/3267], Loss: 1.7160923480987549\n",
            "Epoch [1/1], Step [2100/3267], Loss: 1.5452839136123657\n",
            "Epoch [1/1], Step [2110/3267], Loss: 1.6780940294265747\n",
            "Epoch [1/1], Step [2120/3267], Loss: 1.8129072189331055\n",
            "Epoch [1/1], Step [2130/3267], Loss: 1.5011471509933472\n",
            "Epoch [1/1], Step [2140/3267], Loss: 1.6996301412582397\n",
            "Epoch [1/1], Step [2150/3267], Loss: 1.6204570531845093\n",
            "Epoch [1/1], Step [2160/3267], Loss: 1.5681366920471191\n",
            "Epoch [1/1], Step [2170/3267], Loss: 1.3877320289611816\n",
            "Epoch [1/1], Step [2180/3267], Loss: 1.2411291599273682\n",
            "Epoch [1/1], Step [2190/3267], Loss: 1.5024080276489258\n",
            "Epoch [1/1], Step [2200/3267], Loss: 1.4831304550170898\n",
            "Epoch [1/1], Step [2210/3267], Loss: 1.6387354135513306\n",
            "Epoch [1/1], Step [2220/3267], Loss: 1.5812612771987915\n",
            "Epoch [1/1], Step [2230/3267], Loss: 1.3691684007644653\n",
            "Epoch [1/1], Step [2240/3267], Loss: 1.382287621498108\n",
            "Epoch [1/1], Step [2250/3267], Loss: 1.397386074066162\n",
            "Epoch [1/1], Step [2260/3267], Loss: 1.3286560773849487\n",
            "Epoch [1/1], Step [2270/3267], Loss: 1.731390357017517\n",
            "Epoch [1/1], Step [2280/3267], Loss: 1.5840437412261963\n",
            "Epoch [1/1], Step [2290/3267], Loss: 1.4451431035995483\n",
            "Epoch [1/1], Step [2300/3267], Loss: 1.3891264200210571\n",
            "Epoch [1/1], Step [2310/3267], Loss: 1.6913784742355347\n",
            "Epoch [1/1], Step [2320/3267], Loss: 1.5312514305114746\n",
            "Epoch [1/1], Step [2330/3267], Loss: 1.523620843887329\n",
            "Epoch [1/1], Step [2340/3267], Loss: 1.6181128025054932\n",
            "Epoch [1/1], Step [2350/3267], Loss: 1.4973700046539307\n",
            "Epoch [1/1], Step [2360/3267], Loss: 1.6300513744354248\n",
            "Epoch [1/1], Step [2370/3267], Loss: 1.7282788753509521\n",
            "Epoch [1/1], Step [2380/3267], Loss: 1.543915867805481\n",
            "Epoch [1/1], Step [2390/3267], Loss: 1.3584145307540894\n",
            "Epoch [1/1], Step [2400/3267], Loss: 1.4365366697311401\n",
            "Epoch [1/1], Step [2410/3267], Loss: 1.4691094160079956\n",
            "Epoch [1/1], Step [2420/3267], Loss: 1.509559154510498\n",
            "Epoch [1/1], Step [2430/3267], Loss: 1.5319267511367798\n",
            "Epoch [1/1], Step [2440/3267], Loss: 1.5827257633209229\n",
            "Epoch [1/1], Step [2450/3267], Loss: 1.7426882982254028\n",
            "Epoch [1/1], Step [2460/3267], Loss: 1.702652931213379\n",
            "Epoch [1/1], Step [2470/3267], Loss: 1.444100260734558\n",
            "Epoch [1/1], Step [2480/3267], Loss: 1.5707966089248657\n",
            "Epoch [1/1], Step [2490/3267], Loss: 1.8229455947875977\n",
            "Epoch [1/1], Step [2500/3267], Loss: 1.5308090448379517\n",
            "Epoch [1/1], Step [2510/3267], Loss: 1.7773979902267456\n",
            "Epoch [1/1], Step [2520/3267], Loss: 1.3666362762451172\n",
            "Epoch [1/1], Step [2530/3267], Loss: 1.591927170753479\n",
            "Epoch [1/1], Step [2540/3267], Loss: 1.5967211723327637\n",
            "Epoch [1/1], Step [2550/3267], Loss: 1.5176637172698975\n",
            "Epoch [1/1], Step [2560/3267], Loss: 1.4511382579803467\n",
            "Epoch [1/1], Step [2570/3267], Loss: 1.5430841445922852\n",
            "Epoch [1/1], Step [2580/3267], Loss: 1.6438069343566895\n",
            "Epoch [1/1], Step [2590/3267], Loss: 1.6218347549438477\n",
            "Epoch [1/1], Step [2600/3267], Loss: 1.8511974811553955\n",
            "Epoch [1/1], Step [2610/3267], Loss: 1.5313506126403809\n",
            "Epoch [1/1], Step [2620/3267], Loss: 1.458444595336914\n",
            "Epoch [1/1], Step [2630/3267], Loss: 1.5806684494018555\n",
            "Epoch [1/1], Step [2640/3267], Loss: 1.5176409482955933\n",
            "Epoch [1/1], Step [2650/3267], Loss: 1.5634413957595825\n",
            "Epoch [1/1], Step [2660/3267], Loss: 1.5916646718978882\n",
            "Epoch [1/1], Step [2670/3267], Loss: 1.8095909357070923\n",
            "Epoch [1/1], Step [2680/3267], Loss: 1.4779776334762573\n",
            "Epoch [1/1], Step [2690/3267], Loss: 1.5387377738952637\n",
            "Epoch [1/1], Step [2700/3267], Loss: 1.4607056379318237\n",
            "Epoch [1/1], Step [2710/3267], Loss: 1.379246711730957\n",
            "Epoch [1/1], Step [2720/3267], Loss: 1.6440593004226685\n",
            "Epoch [1/1], Step [2730/3267], Loss: 1.303414225578308\n",
            "Epoch [1/1], Step [2740/3267], Loss: 1.8245341777801514\n",
            "Epoch [1/1], Step [2750/3267], Loss: 1.4593288898468018\n",
            "Epoch [1/1], Step [2760/3267], Loss: 1.5666449069976807\n",
            "Epoch [1/1], Step [2770/3267], Loss: 1.639459252357483\n",
            "Epoch [1/1], Step [2780/3267], Loss: 1.4463822841644287\n",
            "Epoch [1/1], Step [2790/3267], Loss: 1.5363085269927979\n",
            "Epoch [1/1], Step [2800/3267], Loss: 1.4925098419189453\n",
            "Epoch [1/1], Step [2810/3267], Loss: 1.5353562831878662\n",
            "Epoch [1/1], Step [2820/3267], Loss: 1.5248169898986816\n",
            "Epoch [1/1], Step [2830/3267], Loss: 1.302382469177246\n",
            "Epoch [1/1], Step [2840/3267], Loss: 1.405996561050415\n",
            "Epoch [1/1], Step [2850/3267], Loss: 1.816591501235962\n",
            "Epoch [1/1], Step [2860/3267], Loss: 1.4720441102981567\n",
            "Epoch [1/1], Step [2870/3267], Loss: 1.503915786743164\n",
            "Epoch [1/1], Step [2880/3267], Loss: 1.5853606462478638\n",
            "Epoch [1/1], Step [2890/3267], Loss: 1.692405104637146\n",
            "Epoch [1/1], Step [2900/3267], Loss: 1.5878283977508545\n",
            "Epoch [1/1], Step [2910/3267], Loss: 1.4628931283950806\n",
            "Epoch [1/1], Step [2920/3267], Loss: 1.8308144807815552\n",
            "Epoch [1/1], Step [2930/3267], Loss: 1.608129858970642\n",
            "Epoch [1/1], Step [2940/3267], Loss: 1.6451950073242188\n",
            "Epoch [1/1], Step [2950/3267], Loss: 1.7632139921188354\n",
            "Epoch [1/1], Step [2960/3267], Loss: 1.6748037338256836\n",
            "Epoch [1/1], Step [2970/3267], Loss: 1.7065494060516357\n",
            "Epoch [1/1], Step [2980/3267], Loss: 1.8446310758590698\n",
            "Epoch [1/1], Step [2990/3267], Loss: 1.5197782516479492\n",
            "Epoch [1/1], Step [3000/3267], Loss: 1.4791538715362549\n",
            "Epoch [1/1], Step [3010/3267], Loss: 1.6028027534484863\n",
            "Epoch [1/1], Step [3020/3267], Loss: 1.5248481035232544\n",
            "Epoch [1/1], Step [3030/3267], Loss: 1.5247018337249756\n",
            "Epoch [1/1], Step [3040/3267], Loss: 1.6531503200531006\n",
            "Epoch [1/1], Step [3050/3267], Loss: 1.796352744102478\n",
            "Epoch [1/1], Step [3060/3267], Loss: 1.58891761302948\n",
            "Epoch [1/1], Step [3070/3267], Loss: 1.5715522766113281\n",
            "Epoch [1/1], Step [3080/3267], Loss: 1.2633142471313477\n",
            "Epoch [1/1], Step [3090/3267], Loss: 1.3650736808776855\n",
            "Epoch [1/1], Step [3100/3267], Loss: 1.828323483467102\n",
            "Epoch [1/1], Step [3110/3267], Loss: 1.6267507076263428\n",
            "Epoch [1/1], Step [3120/3267], Loss: 1.7674821615219116\n",
            "Epoch [1/1], Step [3130/3267], Loss: 1.5421828031539917\n",
            "Epoch [1/1], Step [3140/3267], Loss: 1.3001340627670288\n",
            "Epoch [1/1], Step [3150/3267], Loss: 1.4744538068771362\n",
            "Epoch [1/1], Step [3160/3267], Loss: 1.3419264554977417\n",
            "Epoch [1/1], Step [3170/3267], Loss: 1.4784443378448486\n",
            "Epoch [1/1], Step [3180/3267], Loss: 1.5624756813049316\n",
            "Epoch [1/1], Step [3190/3267], Loss: 1.4542969465255737\n",
            "Epoch [1/1], Step [3200/3267], Loss: 1.5951734781265259\n",
            "Epoch [1/1], Step [3210/3267], Loss: 1.4618284702301025\n",
            "Epoch [1/1], Step [3220/3267], Loss: 1.5653938055038452\n",
            "Epoch [1/1], Step [3230/3267], Loss: 1.6178640127182007\n",
            "Epoch [1/1], Step [3240/3267], Loss: 1.5409764051437378\n",
            "Epoch [1/1], Step [3250/3267], Loss: 1.660609483718872\n",
            "Epoch [1/1], Step [3260/3267], Loss: 1.9037303924560547\n",
            "Training finished!\n"
          ]
        }
      ],
      "source": [
        "# Loading preprocessed data in train_dataset\n",
        "input_ids = torch.tensor(train_dataset['input_ids']).to(device)\n",
        "labels_0 = torch.tensor(train_dataset['labels']).to(device)\n",
        "\n",
        "# Define your model\n",
        "input_size = len(tokenizer.get_vocab())\n",
        "hidden_size = 512\n",
        "embedding_size = 512\n",
        "output_size = len(tokenizer.get_vocab())\n",
        "\n",
        "\n",
        "encoder = Encoder(input_size, embedding_size, hidden_size)\n",
        "decoder = Decoder(output_size, embedding_size, hidden_size)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "# Define your loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 1\n",
        "batch_size = 32\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(input_ids), batch_size):\n",
        "        inputs = input_ids[i:i+batch_size]\n",
        "        targets = labels_0[i:i+batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, targets)\n",
        "        output = outputs.view(-1, outputs.shape[-1])\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        loss = criterion(outputs.view(-1, output_size), targets.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i // batch_size) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i // batch_size}/{len(input_ids) // batch_size}], Loss: {loss.item()}')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"seq2seq_rnn_model.pth\")\n",
        "print('Training finished!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model\n",
        "loaded_model = Seq2Seq(Encoder(input_size, embedding_size, hidden_size),\n",
        "                       Decoder(output_size, embedding_size, hidden_size))\n",
        "loaded_model.load_state_dict(torch.load(\"seq2seq_rnn_model.pth\"))\n",
        "loaded_model.eval()\n",
        "loaded_model.to(device)\n",
        "\n",
        "# Assuming you have an unseen data preprocessing function\n",
        "def preprocess_unseen_data(unseen_data, tokenizer):\n",
        "    inputs = tokenizer(unseen_data, return_tensors='pt', max_length=64, truncation=True, padding=\"max_length\")\n",
        "    return inputs\n",
        "\n",
        "# Placeholder for unseen data\n",
        "unseen_data = [\"Here's the unseen data that needs to be predicted!!!\"]\n",
        "\n",
        "# Preprocess unseen data\n",
        "unseen_inputs = preprocess_unseen_data(unseen_data, tokenizer)\n",
        "src_seq = unseen_inputs['input_ids'].to(device)\n",
        "\n",
        "# Placeholder for target sequence (trg_seq) during inference\n",
        "max_target_length = input_size\n",
        "\n",
        "trg_seq = torch.zeros((src_seq.shape[0], max_target_length), dtype=torch.long).to(device)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    predictions = loaded_model(src_seq, trg_seq)\n",
        "\n",
        "# Decode predictions\n",
        "def decode_predictions(outputs, tokenizer):\n",
        "    predicted_ids = torch.argmax(outputs, dim=-1)\n",
        "    predicted_text = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "    return predicted_text\n",
        "\n",
        "decoded_predictions = decode_predictions(predictions, tokenizer)  # Implement or use your decoding function\n",
        "\n",
        "# Print the results\n",
        "for input_text, output_text in zip(unseen_data, decoded_predictions):\n",
        "    print(f'Input: {input_text}')\n",
        "    print(f'Predicted Output: {output_text}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wWR00gprXN8",
        "outputId": "53bc7f82-92fd-479a-d72c-894a766a6bac"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Here's the unseen data that needs to be predicted!!!\n",
            "Predicted Output: is be be be the be.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCO8S9p_6aD1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}